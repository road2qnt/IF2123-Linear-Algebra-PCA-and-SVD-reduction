{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7863301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ANALISIS ALJABAR LINEAR: ST. KASUS 1: DATA EKONOMI ---\n",
      "Dimensi Matriks Awal (A): 200 x 50\n",
      "Matriks U (Orthogonal Basis): (200, 50)\n",
      "Vektor Singular Values (Sigma): (50,)\n",
      "Matriks V^T (Feature Weights): (50, 50)\n",
      "Variansi Terjelaskan oleh 5 Komponen: 95.03%\n",
      "Reconstruction Error (Frobenius Norm): 9.3855\n",
      "\n",
      "--- ANALISIS ALJABAR LINEAR: ST. KASUS 2: SENSOR NOISY ---\n",
      "Dimensi Matriks Awal (A): 100 x 30\n",
      "Matriks U (Orthogonal Basis): (100, 30)\n",
      "Vektor Singular Values (Sigma): (30,)\n",
      "Matriks V^T (Feature Weights): (30, 30)\n",
      "Variansi Terjelaskan oleh 3 Komponen: 52.55%\n",
      "Reconstruction Error (Frobenius Norm): 24.6459\n",
      "Std Dev Awal (Noisy): 0.6575\n",
      "Std Dev Hasil Filter (Clean): 0.4794 (Lebih stabil)\n",
      "\n",
      "--- ANALISIS ALJABAR LINEAR: ST. KASUS 3: FITUR SAHAM ---\n",
      "Dimensi Matriks Awal (A): 150 x 40\n",
      "Matriks U (Orthogonal Basis): (150, 40)\n",
      "Vektor Singular Values (Sigma): (40,)\n",
      "Matriks V^T (Feature Weights): (40, 40)\n",
      "Variansi Terjelaskan oleh 8 Komponen: 94.60%\n",
      "Reconstruction Error (Frobenius Norm): 62.1462\n",
      "\n",
      "--- ANALISIS ALJABAR LINEAR: ST. KASUS 4: CITRA DIGITAL ---\n",
      "Dimensi Matriks Awal (A): 512 x 512\n",
      "Matriks U (Orthogonal Basis): (512, 512)\n",
      "Vektor Singular Values (Sigma): (512,)\n",
      "Matriks V^T (Feature Weights): (512, 512)\n",
      "Variansi Terjelaskan oleh 50 Komponen: 100.00%\n",
      "Reconstruction Error (Frobenius Norm): 0.0000\n",
      "Rasio Kompresi Data: 5.12x Lebih Kecil\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fungsi Utilitas untuk Aljabar Linear \"Hardcore\"\n",
    "def svd_analysis(matrix, k_components, title):\n",
    "    print(f\"\\n--- ANALISIS ALJABAR LINEAR: {title} ---\")\n",
    "    \n",
    "    # 1. Representasi Matriks (m x n)\n",
    "    m, n = matrix.shape\n",
    "    print(f\"Dimensi Matriks Awal (A): {m} x {n}\")\n",
    "    \n",
    "    # 2. Centering / Mean Subtraction (Penting untuk PCA/SVD)\n",
    "    # Rumus: X_centered = X - mean(X)\n",
    "    mean_vec = np.mean(matrix, axis=0)\n",
    "    matrix_centered = matrix - mean_vec\n",
    "    \n",
    "    # 3. Dekomposisi SVD Murni\n",
    "    # Rumus: A = U . Sigma . Vt\n",
    "    U, S, Vt = np.linalg.svd(matrix_centered, full_matrices=False)\n",
    "    \n",
    "    # Tampilkan Struktur Matriks Hasil Dekomposisi\n",
    "    print(f\"Matriks U (Orthogonal Basis): {U.shape}\")\n",
    "    print(f\"Vektor Singular Values (Sigma): {S.shape}\")\n",
    "    print(f\"Matriks V^T (Feature Weights): {Vt.shape}\")\n",
    "    \n",
    "    # 4. Hitung Explained Variance Ratio (EVR) secara Manual\n",
    "    # Rumus: Variansi_i = (S_i^2) / (m-1)\n",
    "    eigenvalues = (S ** 2) / (m - 1)\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    explained_variance_ratio = eigenvalues / total_variance\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "    \n",
    "    print(f\"Variansi Terjelaskan oleh {k_components} Komponen: {cumulative_variance[k_components-1]*100:.2f}%\")\n",
    "    \n",
    "    # 5. Rekonstruksi Low-Rank (Approximation)\n",
    "    # Rumus: A_k = U_k . Sigma_k . Vt_k\n",
    "    U_k = U[:, :k_components]\n",
    "    S_k = np.diag(S[:k_components]) # Ubah vektor ke matriks diagonal\n",
    "    Vt_k = Vt[:k_components, :]\n",
    "    \n",
    "    matrix_reconstructed = np.dot(np.dot(U_k, S_k), Vt_k) + mean_vec\n",
    "    \n",
    "    # 6. Hitung Error Rekonstruksi (Frobenius Norm)\n",
    "    # Rumus: ||A - A_k||_F\n",
    "    error = np.linalg.norm(matrix - matrix_reconstructed, 'fro')\n",
    "    print(f\"Reconstruction Error (Frobenius Norm): {error:.4f}\")\n",
    "    \n",
    "    return matrix_reconstructed\n",
    "\n",
    "# ==========================================\n",
    "# EKSEKUSI 4 STUDI KASUS\n",
    "# ==========================================\n",
    "\n",
    "# --- KASUS 1: EKONOMI (Reduksi Dimensi) ---\n",
    "data_eco = pd.read_csv(\"data_ekonomi.csv\").values\n",
    "# Target: 90% variansi, biasanya tercapai di k kecil karena korelasi tinggi\n",
    "_ = svd_analysis(data_eco, k_components=5, title=\"ST. KASUS 1: DATA EKONOMI\")\n",
    "\n",
    "# --- KASUS 2: SENSOR (Noise Removal) ---\n",
    "data_sensor = pd.read_csv(\"data_sensor.csv\").values\n",
    "# Kita ambil k=3 karena sinyal asli sangat sederhana (sinus), sisanya noise\n",
    "clean_sensor = svd_analysis(data_sensor, k_components=3, title=\"ST. KASUS 2: SENSOR NOISY\")\n",
    "# Bukti Noise Hilang: Bandingkan Standard Deviasi\n",
    "print(f\"Std Dev Awal (Noisy): {np.std(data_sensor):.4f}\")\n",
    "print(f\"Std Dev Hasil Filter (Clean): {np.std(clean_sensor):.4f} (Lebih stabil)\")\n",
    "\n",
    "# --- KASUS 3: SAHAM (Feature Extraction) ---\n",
    "data_stock = pd.read_csv(\"data_saham.csv\").values\n",
    "# Proyeksi ke ruang fitur baru (Z = X . V)\n",
    "# Ini langkah preprocessing untuk input ke Neural Network\n",
    "stock_reconstructed = svd_analysis(data_stock, k_components=8, title=\"ST. KASUS 3: FITUR SAHAM\")\n",
    "\n",
    "# --- KASUS 4: CITRA DIGITAL (Kompresi Matriks) ---\n",
    "data_image = pd.read_csv(\"citra_digital.csv\", header=None).values\n",
    "# Kompresi Ekstrem: dari 512 rank menjadi 50 rank\n",
    "img_compressed = svd_analysis(data_image, k_components=50, title=\"ST. KASUS 4: CITRA DIGITAL\")\n",
    "\n",
    "# Hitung Rasio Kompresi Memori\n",
    "original_size = 512 * 512\n",
    "compressed_size = (512*50) + 50 + (50*512) # U_k + S_k + Vt_k\n",
    "print(f\"Rasio Kompresi Data: {original_size / compressed_size:.2f}x Lebih Kecil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38a8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi Awal: (200, 50)\n",
      "Dimensi Reduksi: (200, 5)\n",
      "Variansi Terjelaskan (k=5): 94.15%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Memuat Dataset Ekonomi (200 wilayah x 50 indikator)\n",
    "# Dataset disimulasikan memiliki korelasi internal yang tinggi\n",
    "data_eco = pd.read_csv(\"data_ekonomi.csv\").values\n",
    "\n",
    "# 2. Standardisasi Data (Penting untuk SVD/PCA)\n",
    "# Menghindari bias akibat perbedaan skala (misal: PDB vs Inflasi)\n",
    "mean_vec = np.mean(data_eco, axis=0)\n",
    "std_vec = np.std(data_eco, axis=0)\n",
    "data_std = (data_eco - mean_vec) / std_vec\n",
    "\n",
    "# 3. Eksekusi SVD (Singular Value Decomposition)\n",
    "# A = U . S . Vt\n",
    "U, S, Vt = np.linalg.svd(data_std, full_matrices=False)\n",
    "\n",
    "# 4. Proyeksi ke Ruang Dimensi Rendah (k=5)\n",
    "k = 5\n",
    "# Matriks W adalah 5 baris pertama dari Vt (basis fitur baru)\n",
    "W = Vt[:k, :].T \n",
    "data_reduced = np.dot(data_std, W)\n",
    "\n",
    "print(f\"Dimensi Awal: {data_std.shape}\")\n",
    "print(f\"Dimensi Reduksi: {data_reduced.shape}\")\n",
    "\n",
    "# 5. Evaluasi Variansi (Cumulative Explained Variance)\n",
    "# Variansi proporsional terhadap kuadrat nilai singular\n",
    "eigenvalues = (S ** 2) / (data_std.shape[0] - 1)\n",
    "total_variance = np.sum(eigenvalues)\n",
    "explained_variance = np.sum(eigenvalues[:k]) / total_variance\n",
    "\n",
    "print(f\"Variansi Terjelaskan (k=5): {explained_variance*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc4f3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviasi Standar Awal (Sinyal + Noise): 0.6575\n",
      "Deviasi Standar Akhir (Sinyal Murni): 0.4769\n",
      "Reduksi Variansi Noise: 27.46%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Memuat Dataset Sensor Noisy\n",
    "# Data ini mengandung pola sinyal sinus yang tertutup noise Gaussian\n",
    "data_sensor = pd.read_csv(\"data_sensor.csv\").values\n",
    "\n",
    "# 2. Dekomposisi SVD\n",
    "# Algoritma memisahkan struktur data menjadi komponen ortogonal\n",
    "U, S, Vt = np.linalg.svd(data_sensor, full_matrices=False)\n",
    "\n",
    "# 3. Rekonstruksi Low-Rank (Filtering)\n",
    "# Kita ambil k=3 karena sinyal fisik biasanya berdimensi rendah\n",
    "k = 3\n",
    "S_clean = np.diag(S[:k])\n",
    "U_clean = U[:, :k]\n",
    "Vt_clean = Vt[:k, :]\n",
    "\n",
    "# A_clean = U_k . S_k . Vt_k\n",
    "data_filtered = np.dot(np.dot(U_clean, S_clean), Vt_clean)\n",
    "\n",
    "# 4. Evaluasi Kuantitatif (Standard Deviation Reduction)\n",
    "std_original = np.std(data_sensor)\n",
    "std_filtered = np.std(data_filtered)\n",
    "noise_reduction = (1 - (std_filtered / std_original)) * 100\n",
    "\n",
    "print(f\"Deviasi Standar Awal (Sinyal + Noise): {std_original:.4f}\")\n",
    "print(f\"Deviasi Standar Akhir (Sinyal Murni): {std_filtered:.4f}\")\n",
    "print(f\"Reduksi Variansi Noise: {noise_reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e666d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi Awal (Fitur Teknikal): (150, 40)\n",
      "Dimensi Akhir (Latent Features): (150, 8)\n",
      "Informasi Pasar yang Dipertahankan: 94.53%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Memuat Dataset Saham (150 hari x 40 indikator)\n",
    "# Data ini memiliki multikolinearitas tinggi (banyak indikator mirip)\n",
    "data_stock = pd.read_csv(\"data_saham.csv\").values\n",
    "\n",
    "# 2. Standardisasi (Z-Score)\n",
    "# Penting agar indikator dengan satuan berbeda (Rp vs %) setara\n",
    "mean_vec = np.mean(data_stock, axis=0)\n",
    "std_vec = np.std(data_stock, axis=0)\n",
    "data_std = (data_stock - mean_vec) / std_vec\n",
    "\n",
    "# 3. Dekomposisi SVD\n",
    "U, S, Vt = np.linalg.svd(data_std, full_matrices=False)\n",
    "\n",
    "# 4. Konstruksi Matriks Proyeksi (k=8)\n",
    "# Kita mereduksi fitur sebesar 80% (dari 40 ke 8)\n",
    "k = 8\n",
    "W = Vt[:k, :].T  # Transpose dari Vt untuk mendapatkan bobot proyeksi\n",
    "\n",
    "# 5. Transformasi ke Ruang Fitur Baru (Latent Space)\n",
    "# Z = X . W\n",
    "features_extracted = np.dot(data_std, W)\n",
    "\n",
    "print(f\"Dimensi Awal (Fitur Teknikal): {data_std.shape}\")\n",
    "print(f\"Dimensi Akhir (Latent Features): {features_extracted.shape}\")\n",
    "\n",
    "# 6. Hitung Retensi Informasi\n",
    "eigenvalues = (S ** 2) / (data_stock.shape[0] - 1)\n",
    "explained_variance = np.sum(eigenvalues[:k]) / np.sum(eigenvalues)\n",
    "print(f\"Informasi Pasar yang Dipertahankan: {explained_variance*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
